{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from pypots.imputation import SAITS\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import seaborn_qqplot as sqp\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../params.json', 'r') as file :\n",
    "    params = json.load(file)\n",
    "\n",
    "DATASET, VERSION, DATA_FOLD = params['dataset'], params['version'], params['data_folder']\n",
    "\n",
    "print(f'Working on {DATASET} dataset {VERSION}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_folder = f'{DATA_FOLD}/{VERSION}/3.analysis/outliers/{DATASET}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "impute = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMPUTED_DATASET = f'{DATA_FOLD}/{VERSION}/3.analysis/imputation_48/{DATASET}/tables/first_48_with_static_imputed_saits.parquet'\n",
    "ORIGINAL_DATASET = f'{DATA_FOLD}/{VERSION}/3.analysis/imputation_48/{DATASET}/first_48h_with_static.parquet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imputed = pl.read_parquet(IMPUTED_DATASET)\n",
    "df_original = pl.read_parquet(ORIGINAL_DATASET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.fit(df_imputed.to_numpy()[:,2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imputed.to_numpy()[:,2:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_3d_array(df):\n",
    "    array_df =(\n",
    "        df\n",
    "            .select(pl.col('heart_rate', 'spo2', 'fr', 'pam',\n",
    "       'gender', 'age', 'admission_type'))\n",
    "            .to_numpy()\n",
    "    )\n",
    "    array_df = scaler.transform(array_df)\n",
    "\n",
    "    array_df = array_df.reshape(-1, 48, 7)\n",
    "\n",
    "    return array_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imputed_3d = to_3d_array(df_imputed)\n",
    "df_original_3d = to_3d_array(df_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.isnan(df_original_3d) ^ np.isnan(df_imputed_3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if impute:\n",
    "    n_steps, n_features = df_original_3d.shape[1], df_original_3d.shape[2]\n",
    "\n",
    "    saits = SAITS(\n",
    "        n_steps=n_steps, n_features=n_features,\n",
    "        n_layers=3, d_model=512, d_ffn=128, n_heads=8, d_k=64, d_v=64\n",
    "        )\n",
    "    saits.load(path=f'{DATA_FOLD}/{VERSION}/4.models/imputation/mimic/saits/saits_two_days_with_val.pypots')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imputed_3d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = df_imputed_3d[:,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "impute = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if impute:\n",
    "    errors = np.zeros_like(test_data, dtype=float)\n",
    "    imputed_values = np.full_like(test_data, fill_value=np.nan, dtype=float)\n",
    "\n",
    "    num_series, seq_length, num_features = test_data.shape\n",
    "\n",
    "    for i in tqdm(range(num_series), desc=\"Processing series\"):\n",
    "        for t in range(seq_length):\n",
    "            for f in range(num_features):\n",
    "                if mask[i, t, f] == 0:\n",
    "                    data_temp = test_data[i].copy()\n",
    "                    data_temp[t, f] = np.nan\n",
    "                    data_temp = data_temp.reshape(1, seq_length, num_features)\n",
    "\n",
    "                    imputed_series = saits.impute({'X': data_temp})\n",
    "                    imputed_value = imputed_series[0, t, f]\n",
    "\n",
    "                    errors[i, t, f] = test_data[i, t, f] - imputed_value\n",
    "                    imputed_values[i, t, f] = imputed_value\n",
    "                else:\n",
    "                    errors[i, t, f] = 1\n",
    "                    imputed_values[i, t, f] = np.nan\n",
    "\n",
    "    # Déstandardisation\n",
    "    errors_reshaped = errors.reshape(-1, num_features)\n",
    "    imputed_reshaped = imputed_values.reshape(-1, num_features)\n",
    "\n",
    "    errors_reshaped = scaler.inverse_transform(errors_reshaped)\n",
    "    imputed_reshaped = scaler.inverse_transform(imputed_reshaped)\n",
    "\n",
    "    # Création des colonnes id et intervalle\n",
    "    ids = np.repeat(np.arange(num_series), seq_length)\n",
    "    intervalles = np.tile(np.arange(seq_length), num_series)\n",
    "\n",
    "    # Construction des DataFrames\n",
    "    columns = [f'f{i+1}' for i in range(num_features)]\n",
    "    df_score_sample = pl.DataFrame({\n",
    "        'id': ids,\n",
    "        'intervalle': intervalles,\n",
    "        **{columns[i]: errors_reshaped[:, i] for i in range(num_features)}\n",
    "    })\n",
    "\n",
    "    df_imputed_values = pl.DataFrame({\n",
    "        'id': ids,\n",
    "        'intervalle': intervalles,\n",
    "        **{columns[i]: imputed_reshaped[:, i] for i in range(num_features)}\n",
    "    })\n",
    "\n",
    "    df_score_sample.write_csv(results_folder + '/datasets/saits_errors.csv')\n",
    "    df_imputed_values.write_csv(results_folder + '/datasets/saits_full_imputed_values.csv')\n",
    "\n",
    "    errors_numpy = df_score_sample.select(columns).to_numpy()\n",
    "    imputed_numpy = df_imputed_values.select(columns).to_numpy()\n",
    "\n",
    "else:\n",
    "    df_score_sample = pl.read_csv(results_folder + '/datasets/saits_errors.csv')\n",
    "    df_imputed_values = pl.read_csv(results_folder + '/datasets/saits_full_imputed_values.csv')\n",
    "\n",
    "    columns = [col for col in df_score_sample.columns if col not in ('id', 'intervalle')]\n",
    "\n",
    "    errors_numpy = df_score_sample.select(columns).to_numpy()\n",
    "    imputed_numpy = df_imputed_values.select(columns).to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_1d = errors_numpy.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "print(skew(error_1d))\n",
    "print(kurtosis(error_1d))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'error' : error_1d}\n",
    "error_pd = pd.DataFrame(data).sort_values(by = 'error').reset_index(drop=True)\n",
    "error_pd['pos'] = range(len(error_pd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.histplot(error_1d, binwidth=0.05)\n",
    "\n",
    "plt.xlim(-3, 3)\n",
    "plt.ylim(0,800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_error = error_1d.mean()\n",
    "std_error = error_1d.std()\n",
    "error_normalize = (error_1d - mean_error)/std_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(error_normalize)\n",
    "\n",
    "plt.xlim(-5, 5)\n",
    "plt.ylim(0,15000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import pylab as py\n",
    "\n",
    "sm.qqplot(error_1d, line ='45') \n",
    "py.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_score_sample = pl.DataFrame(errors.to_numpy().reshape(-1, 6))\n",
    "df_score_sample.write_csv(results_folder + '/datasets/saits_errors_imputed_mimic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_data = scaler.inverse_transform(test_data.reshape(-1, 7))\n",
    "reshaped_display_data = display_data.reshape(-1, 48, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_3d = errors_numpy.reshape(-1,48,7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "math.erf(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_error = norm.sf(np.abs(error_3d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_patient = df_imputed_values.to_numpy().reshape(-1,48,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.2\n",
    "exp_error = 1 - np.exp(-alpha * error_3d**2)\n",
    "#exp_error[mask[:,:,:]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_feature = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synth_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scores = errors.reshape(-1,48,6)\n",
    "selected_patient = 883\n",
    "selected_patient = int(np.random.choice(np.where(np.abs(exp_error[:,:,selected_feature]))[0]))\n",
    "\n",
    "\n",
    "timestamps = np.arange(48)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, sharex=True, figsize=(12, 8))\n",
    "\n",
    "patient_data = reshaped_display_data[selected_patient,:,selected_feature]\n",
    "error_value = exp_error[selected_patient,:,selected_feature]\n",
    "synth_value = synthetic_patient[selected_patient,:,selected_feature]\n",
    "\n",
    "# Premier subplot : valeurs du patient\n",
    "ax1.plot(timestamps, patient_data, marker='o', label='Valeur de la variable')\n",
    "ax1.set_ylabel('Valeur')\n",
    "ax1.set_ylim(0, 200)\n",
    "ax1.grid(True)\n",
    "\n",
    "\n",
    "# Second subplot : variation du score\n",
    "ax2.plot(timestamps, synth_value, marker='o', color='red', label='Score')\n",
    "ax2.set_title('Error')\n",
    "ax2.set_xlabel('Temps')\n",
    "ax2.set_ylabel('Erreur')\n",
    "ax2.set_ylim(0, 300)\n",
    "ax2.grid(True)\n",
    "\n",
    "\n",
    "\n",
    "# Ajustement des espacements pour éviter le chevauchement des labels/titres\n",
    "plt.tight_layout()\n",
    "\n",
    "fig.suptitle(f\"patient {selected_patient}, variable {df_imputed[:,2:].columns[selected_feature]}\")\n",
    "# Affichage du graphique\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, sharex=True, figsize=(12, 8))\n",
    "\n",
    "patient_data = reshaped_display_data[selected_patient,:,selected_feature]\n",
    "patient_scores = scores[selected_patient,:,selected_feature]\n",
    "\n",
    "# Premier subplot : valeurs du patient\n",
    "ax1.plot(timestamps, patient_data, marker='o', label='Valeur de la variable')\n",
    "ax1.set_ylabel('Valeur')\n",
    "ax1.grid(True)\n",
    "\n",
    "# Second subplot : variation du score\n",
    "ax2.plot(timestamps, patient_scores, marker='o', color='red', label='Score')\n",
    "ax2.set_title('Variation du score')\n",
    "ax2.set_xlabel('Temps')\n",
    "ax2.set_ylabel('Score')\n",
    "ax2.set_ylim(0, 1)\n",
    "ax2.grid(True)\n",
    "\n",
    "# Ajustement des espacements pour éviter le chevauchement des labels/titres\n",
    "plt.tight_layout()\n",
    "\n",
    "fig.suptitle(f\"patient {selected_patient}, variable {df_imputed[:,2:].columns[selected_feature]}\")\n",
    "# Affichage du graphique\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
