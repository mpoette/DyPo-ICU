{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "\n",
    "import lightning as L\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import json\n",
    "import polars as pl\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../params.json', 'r') as file :\n",
    "    params = json.load(file)\n",
    "\n",
    "DATASET, VERSION, DATA_FOLD = params['dataset'], params['version'], params['data_folder']\n",
    "\n",
    "print(f'Working on {DATASET} dataset {VERSION}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMPUTED_DATASET = f'{DATA_FOLD}/{VERSION}/3.analysis/imputation_48/{DATASET}/tables/first_48_with_static_imputed_saits.parquet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_data = pl.read_parquet(IMPUTED_DATASET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo = pl.read_parquet('/data2/poette.m/dypo/v4/2.clean_data/chu/static/clean_static_encounters.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data = (demo\n",
    "    .filter(\n",
    "        pl.col('gender').is_in(['Masculin', 'FÃ©minin'])\n",
    "        )\n",
    "    .select(\n",
    "        'encounterId', 'gender', 'age', 'admission_type', 'utcInTime', 'date_deces'\n",
    "        )\n",
    "    .cast(\n",
    "        {\n",
    "            'utcInTime' : pl.Date\n",
    "        }\n",
    "    )\n",
    "    .with_columns(\n",
    "        deces_j30 = ((pl.col('date_deces') - pl.col('utcInTime')).dt.total_days() <= 30).fill_null(False)\n",
    "    )\n",
    "    .drop('utcInTime', 'date_deces')\n",
    ")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = time_data.drop('gender', 'age', 'admission_type').join(y_data, on='encounterId', how='inner').to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['admission_type'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "data_trans = data.copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "le = LabelEncoder()\n",
    "\n",
    "numeric_data = ['heart_rate', 'spo2', 'fr', 'pam','age']\n",
    "cat_data = ['gender', 'admission_type', 'deces_j30']\n",
    "for n in numeric_data :\n",
    "    data_trans[n] = scaler.fit_transform(data_trans[[n]])\n",
    "\n",
    "for c in cat_data :\n",
    "    data_trans[c] = le.fit_transform(data_trans[c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_trans.admission_type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encounter_df = data_trans[['encounterId' , 'deces_j30']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(encounter_df, stratify = encounter_df['deces_j30'], test_size=0.3 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = data_trans.drop_duplicates(subset=['encounterId', 'deces_j30', 'intervalle']).drop(columns='deces_j30'), data_trans[['encounterId','deces_j30']].drop_duplicates()\n",
    "\n",
    "\n",
    "X_train_2d = X[X['encounterId'].isin(train['encounterId'])]\n",
    "X_test_2d = X[X['encounterId'].isin(test['encounterId'])]\n",
    "\n",
    "y_train = y[y['encounterId'].isin(train['encounterId'])]['deces_j30'].to_numpy()\n",
    "y_test = y[y['encounterId'].isin(test['encounterId'])]['deces_j30'].to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_2d.drop(columns=['encounterId', 'intervalle']).to_numpy().reshape(-1, 48, 7)\n",
    "X_test = X_test_2d.drop(columns=['encounterId', 'intervalle']).to_numpy().reshape(-1, 48, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor(X_train).to(torch.float32)\n",
    "labels = torch.tensor(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(inputs)\n",
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TensorDataset(inputs, labels)\n",
    "dataloader = DataLoader(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM by Hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LSTM(L.LightningModule):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size=7, hidden_size=1)\n",
    "        self.loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    def forward(self, input):\n",
    "        input = input.permute(1, 0, 2)  # (seq_len, batch, input_size)\n",
    "        lstm_out, _ = self.lstm(input)  # (seq_len, batch, hidden)\n",
    "        return lstm_out[-1].squeeze(-1)  # (batch,)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return Adam(self.parameters(), lr=1e-3)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        input_i, label_i = batch\n",
    "        input_i = input_i.float()\n",
    "        label_i = label_i.float()\n",
    "        output_i = self(input_i)\n",
    "        loss = self.loss_fn(output_i, label_i)\n",
    "\n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        input_i, label_i = batch\n",
    "        input_i = input_i.float()\n",
    "        label_i = label_i.float()\n",
    "        output_i = self(input_i)\n",
    "        loss = self.loss_fn(output_i, label_i)\n",
    "\n",
    "        preds = torch.sigmoid(output_i) > 0.5\n",
    "        acc = (preds == label_i).float().mean()\n",
    "\n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "        self.log(\"val_acc\", acc, prog_bar=True)\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = L.Trainer(max_epochs=5, log_every_n_steps=2)\n",
    "\n",
    "trainer.fit(model, train_dataloaders=dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = torch.tensor(X_test).to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "arr = (pred - torch.tensor(y_test)).detach().numpy()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
