{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import json\n",
    "\n",
    "QUERIES_FOLDER = \"../1.query/extended_demography/\"\n",
    "OUTPUT_FOLDER = \"../2.rawDataset/extended_demography/\"\n",
    "SERVER = 'SVM-ICCA-REP'\n",
    "DATABASE = 'CISReportingDB'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encounters = pl.read_parquet('../4.preparedDatasets/prepared_dataset_2024-11-08.parquet').select(\"encounterId\", \"utcInTime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_uri = f'mssql://@{SERVER}/{DATABASE}?trusted_connection=true'\n",
    "\n",
    "query = open(QUERIES_FOLDER + 'generic_query.sql').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(QUERIES_FOLDER + 'features.json', 'r', encoding='utf-8') as f :\n",
    "    variables_json = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Génération des datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automatisée via JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for variable in variables_json :\n",
    "    propname = variables_json[variable]['dictionary_propname']\n",
    "    table = variables_json[variable]['table']\n",
    "    feature = variables_json[variable]\n",
    "    query_formatted = query.format(\n",
    "        dictionaryPropName = f\"'{propname}'\",\n",
    "        feature = f\"'{variable}'\",\n",
    "        feature_table = table\n",
    "    )\n",
    "    try :\n",
    "        feature_data = pl.read_database_uri(query_formatted, conn_uri, engine='connectorx')\n",
    "        print(f'Extraction {variable} : OK')\n",
    "    except :\n",
    "        raise\n",
    "\n",
    "    with_time_delta = feature_data.with_columns(\n",
    "        pl.col('encounterId').cast(pl.String)\n",
    "    ).join(\n",
    "        encounters, on='encounterId', how=\"inner\"\n",
    "    ).with_columns(\n",
    "        (((pl.col('utcChartTime') - pl.col('utcInTime')).dt.total_minutes())/60).alias('delta_inTime_hours')\n",
    "    ).sort('encounterId', 'utcChartTime')\n",
    "    try :\n",
    "        with_time_delta.write_parquet(f'{OUTPUT_FOLDER}{variable}.parquet')\n",
    "        print(f'Sauvegarde {variable} : OK  / Dataset shape : {with_time_delta.shape}')\n",
    "    except :\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for variable in variables_json :\n",
    "    print(variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_data = pl.read_database_uri(query, conn_uri, engine='connectorx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_time_delta = feature_data.with_columns(\n",
    "    pl.col('encounterId').cast(pl.String)\n",
    ").join(\n",
    "    encounters, on='encounterId', how=\"inner\"\n",
    "    ).with_columns(\n",
    "        (((pl.col('utcChartTime') - pl.col('utcInTime')).dt.total_minutes())/60).alias('delta_inTime_hours')\n",
    "    ).sort('encounterId', 'utcChartTime')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_time_delta.write_parquet('../2.rawDataset/dynamic_features/map_invasive.parquet')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
