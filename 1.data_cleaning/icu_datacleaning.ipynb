{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import os\n",
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../params.json', 'r') as file :\n",
    "    params = json.load(file)\n",
    "\n",
    "DATASET, VERSION = params['dataset'], params['version']\n",
    "DATA_FOLD = params['data_folder']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_FOLDER = f'{DATA_FOLD}/{VERSION}/1.raw_data/{DATASET}/'\n",
    "OUTPUT_FOLDER = f'{DATA_FOLD}/{VERSION}/2.clean_data/{DATASET}/static/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CENSUS_FILE = 'census/raw_census.parquet'\n",
    "IGS_FILE = 'igs/igs_all.csv'\n",
    "\n",
    "OUTPUT_STATIC_FILE = 'clean_static_encounters.parquet'\n",
    "#_dataset_2024-12-18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Callable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_percentage(value):\n",
    "    try:\n",
    "        clean_value = float(value.replace('Mortalité prédite : ', '').replace('%', '').replace(',', '.')) / 100\n",
    "        return clean_value\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def clean_encounter(value):\n",
    "    try:\n",
    "        remove_letters = re.sub('\\D', '', value)\n",
    "        clean_value = str(int(value))\n",
    "        return remove_letters\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def clean_igs(value):\n",
    "    try:\n",
    "        clean_value = float(value)\n",
    "        return clean_value\n",
    "    except:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pl.read_parquet(INPUT_FOLDER + CENSUS_FILE)\n",
    "df_igs = pl.read_csv(INPUT_FOLDER + IGS_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "raw_data.filter(pl.col('displaylabel').is_in([\n",
    "                'Neuro Surgical Intensive Care Unit (Neuro SICU)',\n",
    "                'Surgical Intensive Care Unit (SICU)',\n",
    "                'Neuro Stepdown',\n",
    "                'Medical/Surgical Intensive Care Unit (MICU/SICU)',\n",
    "                'Cardiac Vascular Intensive Care Unit (CVICU)', #retrait chirurgie CCV pour correspondre au dataset CHU\n",
    "                'Neuro Intermediate',\n",
    "                'Coronary Care Unit (CCU)',\n",
    "                'Medical Intensive Care Unit (MICU)',\n",
    "                'Trauma SICU (TSICU)'\n",
    "                ])).unique('encounterid').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATASET == 'mimic' :\n",
    "    raw_data = raw_data.rename(\n",
    "                    {\n",
    "                        'displaylabel': 'displayLabel',\n",
    "                        'encounterid': 'encounterId',\n",
    "                        'encounternumber': 'encounterNumber',\n",
    "                        'lifetimenumber': 'lifeTimeNumber',\n",
    "                        'dateofdeath' : 'dateOfDeath',\n",
    "                        'isdeceased' : 'isDeceased',\n",
    "                        'utcintime' : 'utcInTime',\n",
    "                        'utcouttime' : 'utcOutTime',\n",
    "                        'lengthofstay' : 'lengthOfStay',\n",
    "                        'height' : 'taille',\n",
    "                        'weight' : 'poids_admission'\n",
    "                    }\n",
    "                ).with_columns(\n",
    "                    [\n",
    "                        pl.lit(None).alias('adresse'),\n",
    "                        pl.lit(None).alias('ville'),\n",
    "                        pl.lit(None).alias('cp'),\n",
    "                        pl.lit(None).alias('dateOfBirth'),\n",
    "                        pl.lit(None).alias('lastName'),\n",
    "                        pl.lit(None).alias('firstName')\n",
    "                    ]\n",
    "                )\n",
    "\n",
    "if DATASET == 'chu' :\n",
    "    raw_data = raw_data.with_columns(\n",
    "                    [\n",
    "                        pl.lit(None).alias('taille'),\n",
    "                        pl.lit(None).alias('poids_admission'),\n",
    "                    ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data['displayLabel'].unique().to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate mortality "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mortality = raw_data.select('encounterId', 'dateOfDeath','isDeceased'\n",
    "                ).filter((pl.col('isDeceased') == True) | (pl.col('dateOfDeath').is_not_null())\n",
    "                         ).group_by('encounterId').agg(\n",
    "                             pl.col('isDeceased').max().alias('isDeceased'),\n",
    "                                pl.col('dateOfDeath').first().alias('dateOfDeath')\n",
    "                ).cast(\n",
    "                    {'encounterId' : pl.String}\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mortality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regroup by Encounter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display units list\n",
    "if DATASET == 'chu' :\n",
    "    icu_units = [ \n",
    "                'PURPAN REA. POLY.',\n",
    "                'IUC REA.', \n",
    "                'NEURO-CHIR REA', \n",
    "                'RANGUEIL REA. POLY.',\n",
    "                'RANGUEIL DECHO. REA.', \n",
    "                'PURPAN DECHO. REA.', \n",
    "                'PURPAN SC. REA.', \n",
    "                'RANGUEIL SC. REA.',\n",
    "                'IUC SC.'\n",
    "                ]\n",
    "    \n",
    "elif DATASET == 'mimic' :\n",
    "    icu_units = [\n",
    "                'Neuro Surgical Intensive Care Unit (Neuro SICU)',\n",
    "                'Surgical Intensive Care Unit (SICU)',\n",
    "                'Neuro Stepdown',\n",
    "                'Medical/Surgical Intensive Care Unit (MICU/SICU)',\n",
    "                #'Cardiac Vascular Intensive Care Unit (CVICU)', retrait chirurgie CCV pour correspondre au dataset CHU\n",
    "                'Neuro Intermediate',\n",
    "                'Coronary Care Unit (CCU)',\n",
    "                'Medical Intensive Care Unit (MICU)',\n",
    "                'Trauma SICU (TSICU)'\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encounter_df = (raw_data\n",
    "                .filter(\n",
    "    # Keeping only ICU (without UTO, paediatric ICU, CCV and Burns)\n",
    "                    pl.col('displayLabel').is_in(icu_units),\n",
    "                    (pl.col('age') >= 18)\n",
    "    # Regroup by encounter and unit\n",
    "                    )\n",
    "                .with_columns(\n",
    "                    #pl.col('encounterId').cast(pl.String).alias('encounterId'),\n",
    "                    pl.col('encounterId').cast(pl.String).map_elements(clean_encounter, return_dtype=pl.String).alias('encounterId')\n",
    "                    )\n",
    "                .sort(by=['encounterId', 'utcInTime'])\n",
    "                .group_by(\n",
    "                    ['encounterId',\n",
    "                    'encounterNumber',\n",
    "                    'lifeTimeNumber',\n",
    "                    'lastName',\n",
    "                    'firstName',\n",
    "                    'gender',\n",
    "                    'age',\n",
    "                    'dateOfBirth']\n",
    "                )\n",
    "                .agg([\n",
    "                    pl.col('utcInTime').min().alias('utcInTime'),\n",
    "                    pl.col('utcOutTime').max().alias('utcOutTime'),\n",
    "                    pl.col(\"displayLabel\")\n",
    "                    .filter((pl.col(\"displayLabel\").is_not_null()))\n",
    "                    .sort_by('utcInTime')\n",
    "                    .first()\n",
    "                    .alias('unitLabel'),\n",
    "                    pl.col('adresse').max().alias('adresse'),\n",
    "                    pl.col('ville').max().alias('ville'),\n",
    "                    pl.col('cp').max().alias('cp'),\n",
    "                    pl.col('taille').first().alias('taille'),\n",
    "                    pl.col('poids_admission').first().alias('poids_admission'),\n",
    "                ])\n",
    "                .join(\n",
    "                    df_mortality, on='encounterId', how='left'\n",
    "                ).with_columns(\n",
    "                    [\n",
    "                        ((((pl.col('utcOutTime').sub(pl.col('utcInTime'))).dt.total_minutes())/60)).round(2).alias('los')\n",
    "                    ]\n",
    "                ).with_columns(\n",
    "                    pl.when(pl.col('isDeceased').is_not_null() | pl.col(\"dateOfDeath\").is_not_null())\n",
    "                    .then(pl.lit(True))\n",
    "                    .otherwise(pl.lit(False))\n",
    "                    .alias(\"isDeceased\")\n",
    "                )\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encounter_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extended demography"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_demo_extended = encounter_df\n",
    "if DATASET == 'chu': \n",
    "    df_demo_extended = df_demo_extended.drop(['taille', 'poids_admission'])\n",
    "    directory = INPUT_FOLDER + 'extended_demography/'\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".parquet\") or filename.endswith(\".csv\"): \n",
    "            df_extended_feature = pl.read_parquet(directory + filename)\n",
    "            print(df_extended_feature.shape)\n",
    "            feature = df_extended_feature.get_column('feature').to_list()[0]\n",
    "            print(feature)\n",
    "            df_extended_feature = df_extended_feature.sort(\n",
    "                            'encounterId', 'utcChartTime'\n",
    "                        ).unique(\n",
    "                            subset=['encounterId'], keep='last'\n",
    "                        )\n",
    "            if feature in ['taille', 'poids_admission'] :\n",
    "                df_extended_feature = df_extended_feature.rename(\n",
    "                        {'valueNumber' : feature}\n",
    "                )\n",
    "            else:\n",
    "                df_extended_feature = df_extended_feature.rename(\n",
    "                        {'valueString' : feature}\n",
    "                )\n",
    "            df_extended_feature = df_extended_feature.select('encounterId', feature)\n",
    "            df_demo_extended = df_demo_extended.join(\n",
    "                            df_extended_feature, on='encounterId', how='left'\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_demo_extended.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IGS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATASET == 'mimic' :\n",
    "    df_igs_clean = (\n",
    "            df_igs  \n",
    "            .rename(\n",
    "                {\n",
    "                    'encounterid': 'encounterId'\n",
    "                    ,'admissiontype_score' : 'admission_type'\n",
    "                }\n",
    "            )\n",
    "            .sort('encounterId', 'sapsii', descending=[False, True])\n",
    "            .unique('encounterId', keep='first')\n",
    "            .with_columns(\n",
    "                pl.when(pl.col('admission_type') == 8)\n",
    "                    .then(pl.lit('Unscheduled Surgery'))\n",
    "                .when(pl.col('admission_type') == 0)\n",
    "                    .then(pl.lit('Scheduled Surgery'))\n",
    "                .when(pl.col('admission_type') == 6)\n",
    "                    .then(pl.lit('Medical'))\n",
    "                .otherwise(None).alias('admission_type')\n",
    "                )\n",
    "            .cast({'encounterId': pl.String})\n",
    "            .select('encounterId', 'admission_type', 'sapsii', 'sapsii_prob')\n",
    "            )\n",
    "    df_demo_extended = df_demo_extended.join(df_igs_clean, on='encounterId', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATASET == 'chu' : \n",
    "\n",
    "    df_igs_clean = (\n",
    "                df_igs  \n",
    "                .with_columns(\n",
    "                        pl.col('encounterNumber').map_elements(clean_encounter, return_dtype=pl.String).alias('encounterNumber'),\n",
    "                        pl.col('igsMort').map_elements(clean_percentage, return_dtype=pl.Float64).alias('sapsii_prob')\n",
    "                        )\n",
    "                .sort('encounterNumber', 'igsStoreTime')\n",
    "                .unique('encounterNumber', keep='first')\n",
    "                .with_columns(\n",
    "                    pl.when(pl.col('igsTypeAdm') == 0)\n",
    "                        .then(pl.lit('Medical'))\n",
    "                    .when(pl.col('igsTypeAdm') == 2)\n",
    "                        .then(pl.lit('Unscheduled Surgery'))\n",
    "                    .when(pl.col('igsTypeAdm') == 1)\n",
    "                        .then(pl.lit('Scheduled Surgery'))\n",
    "                    .otherwise(None).alias('admission_type')\n",
    "                    )\n",
    "                .rename(\n",
    "                    {\n",
    "                    'igsTotal' : 'sapsii'\n",
    "                    }\n",
    "                )\n",
    "                .select('encounterNumber', 'admission_type', 'sapsii', 'sapsii_prob')\n",
    "                )\n",
    "    df_demo_extended = df_demo_extended.join(df_igs_clean, on='encounterNumber', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_igs_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_demo_extended.n_unique('encounterId')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Admission type (from IGS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pseudonymisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_identifiantes = [\n",
    "    'encounterId',\n",
    "    'encounterNumber',\n",
    "    'lifeTimeNumber',\n",
    "    'lastName',\n",
    "    'firstName',\n",
    "    'dateOfBirth',\n",
    "    'cp',\n",
    "    'ville',\n",
    "    'adresse',\n",
    "    'utcInTime',\n",
    "    'utcOutTime',\n",
    "    'dateOfDeath',\n",
    "    'conclusion',\n",
    "    'motif_adm'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATASET == 'chu' : \n",
    "    df_indexed = df_demo_extended.with_row_index(offset=1)\n",
    "    table_corr = df_indexed.select(col_identifiantes)\n",
    "    df_pseudonymised = df_indexed.with_columns(\n",
    "        year_inTime = pl.col('utcInTime').dt.year()\n",
    "    ).select(pl.exclude(col_identifiantes))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_demo_extended.write_parquet(OUTPUT_FOLDER + OUTPUT_STATIC_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATASET == 'chu' : \n",
    "    table_corr.write_csv(OUTPUT_FOLDER + 'correlation_table.csv')\n",
    "    df_pseudonymised.write_parquet(OUTPUT_FOLDER + 'clean_pseudonimysed_dataset.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_demo_extended"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
