{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from matplotlib.colors import Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../params.json', 'r') as file :\n",
    "    params = json.load(file)\n",
    "\n",
    "DATASET, VERSION = params['dataset'], params['version']\n",
    "DATA_FOLD = params['data_folder']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pl.read_parquet(f'{DATA_FOLD}/{VERSION}/3.analysis/imputation_48/{DATASET}/first_48h.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_features = data[['fr', 'heart_rate', 'pam', 'spo2']].to_pandas()\n",
    "round(int(data_features.isna().sum().sum())/(data_features.shape[0]*data_features.shape[1]), 4) *100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer une matrice pivotée pour la heatmap\n",
    "heatmap_data = (\n",
    "    data.select([\"intervalle\", \"encounterId\", \"total_missing\"])\n",
    "    .pivot(\n",
    "        values=\"total_missing\",  # Les valeurs à afficher\n",
    "        index=\"intervalle\",      # Chaque ligne correspond à un intervalle\n",
    "        on=\"encounterId\"    # Chaque colonne correspond à un patient\n",
    "    )\n",
    ")\n",
    "\n",
    "# Convertir en DataFrame Pandas pour la heatmap\n",
    "heatmap_matrix = heatmap_data.to_pandas()\n",
    "\n",
    "# Remplir les valeurs manquantes (None ou null) par NaN\n",
    "heatmap_matrix = heatmap_matrix.fillna(np.nan)\n",
    "\n",
    "# Création de la colormap avec le blanc pour les NaN\n",
    "cmap = plt.cm.coolwarm  # Palette principale\n",
    "cmap.set_bad(color='white')  # Définir la couleur pour les valeurs manquantes\n",
    "\n",
    "# Normalisation pour la plage 0 à 4\n",
    "norm = Normalize(vmin=0, vmax=4)  # Plage fixe pour les valeurs manquantes (0 à 7)\n",
    "\n",
    "# Masquer les NaN dans la matrice\n",
    "masked_matrix = np.ma.masked_where(np.isnan(heatmap_matrix), heatmap_matrix)\n",
    "\n",
    "# Création de la figure\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.imshow(masked_matrix, aspect='auto', cmap=cmap, norm=norm, origin='lower')\n",
    "\n",
    "# Ajouter une barre de couleur\n",
    "cbar = plt.colorbar(label=\"Nombre de variables manquantes\")\n",
    "cbar.set_ticks(range(4))  # Afficher les ticks de 0 à 4\n",
    "cbar.set_label(\"Nombre de variables manquantes\", rotation=270, labelpad=20)\n",
    "\n",
    "# Ajouter des labels et un titre\n",
    "plt.xlabel(\"Séjours\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.ylabel(\"Intervalle (h)\")\n",
    "\n",
    "# Enlever la grille\n",
    "plt.grid(False)\n",
    "\n",
    "# Afficher la figure\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculer le nombre absolu de valeurs manquantes par variable\n",
    "missing_counts = data.select([\n",
    "    pl.col(\"fr\").is_null().sum().alias(\"fr_missing\"),\n",
    "    pl.col(\"heart_rate\").is_null().sum().alias(\"heart_rate_missing\"),\n",
    "    pl.col(\"spo2\").is_null().sum().alias(\"spo2_missing\"),\n",
    "    pl.col(\"pam\").is_null().sum().alias(\"pam_missing\"),\n",
    "    #pl.col(\"pad\").is_null().sum().alias(\"pad_missing\"),\n",
    "    #pl.col(\"pas\").is_null().sum().alias(\"pas_missing\")\n",
    "]).to_pandas()\n",
    "\n",
    "# Calculer le pourcentage de valeurs manquantes par rapport au nombre total d'intervalles\n",
    "total_intervals = data.shape[0]\n",
    "missing_percentages = (missing_counts / total_intervals * 100).round(1)\n",
    "\n",
    "# Afficher les résultats\n",
    "missing_counts = missing_counts.T\n",
    "missing_counts.columns = ['Missing Count']\n",
    "missing_percentages = missing_percentages.T\n",
    "missing_percentages.columns = ['Missing Percentage (%)']\n",
    "\n",
    "missing_stats = pd.concat([missing_counts, missing_percentages], axis=1)\n",
    "print(missing_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md =data_features.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_dict = {}\n",
    "for main_col in md.columns :\n",
    "    corr_dict[main_col] = []\n",
    "    for col in md.columns :\n",
    "       corr = round((md[main_col] & md[col]).sum()/(md[main_col].sum()),2 )\n",
    "       corr_dict[main_col].append(corr)\n",
    "corr_df = pd.DataFrame(corr_dict, index=md.columns)\n",
    "\n",
    "print(corr_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,5) :\n",
    "    total_missing = data.filter((pl.col('max_valid_interval') > 0)).filter(pl.col('total_missing') == i).shape[0]\n",
    "    print(f\"{i} variables manquantes = {total_missing} ({round((total_missing/data.filter((pl.col('max_valid_interval') > 0)).shape[0])*100, 1)}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.filter(pl.col('total_missing') > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set a style suitable for academic publication\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"paper\", font_scale=1.2)\n",
    "\n",
    "# Create the figure and axes\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# Plot the count of intervals with missing data > 0\n",
    "ax = sns.countplot(\n",
    "    data=data.filter(pl.col('total_missing') > 0),\n",
    "    x='total_missing',\n",
    "    color='skyblue',      # You can change this color if you prefer\n",
    "    edgecolor='black'     # Adds a subtle outline to the bars\n",
    ")\n",
    "\n",
    "# Customize labels and title\n",
    "ax.set_xlabel(\"Missing Values per Interval\", fontsize=14)\n",
    "ax.set_ylabel(\"Number of Intervals\", fontsize=14)\n",
    "ax.set_title(\"Distribution of Missing Values per Interval\", fontsize=16, fontweight='bold')\n",
    "\n",
    "# Ensure everything fits nicely\n",
    "plt.tight_layout()\n",
    "\n",
    "# Display the figure\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour calculer les occurrences d'intervalles consécutifs\n",
    "def calculate_consecutive_intervals(data_merge, max_missing_values):\n",
    "    results = {}\n",
    "    df = data_merge.cast({'encounterId' : pl.Int32}).sort('encounterId', 'intervalle').to_pandas()\n",
    "    \n",
    "    for n in range(max_missing_values + 1):  # Tester chaque seuil de n variables manquantes\n",
    "        \n",
    "        df[\"below_threshold\"] = df[\"total_missing\"] >= n\n",
    "\n",
    "        # Identifier les groupes consécutifs où `below_threshold` est True\n",
    "        df[\"group\"] = (df[\"below_threshold\"] != df[\"below_threshold\"].shift()).cumsum()\n",
    "        consecutive_counts = df[df[\"below_threshold\"]].groupby([\"group\", \"encounterId\"]).size()\n",
    "\n",
    "        # Compter les occurrences pour chaque longueur d'intervalle\n",
    "        occurrences = consecutive_counts.value_counts().sort_index()\n",
    "        results[n] = occurrences\n",
    "\n",
    "    # Convertir les résultats en DataFrame\n",
    "    results_df = pd.DataFrame(results).fillna(0).astype(int)\n",
    "    results_df.index.name = \"Consecutive Hours\"\n",
    "    results_df.columns.name = \"Max Missing Values\"\n",
    "    return results_df\n",
    "\n",
    "# Calcul des occurrences pour les seuils de 0 à 7 variables manquantes\n",
    "occurrences_df = calculate_consecutive_intervals(data, max_missing_values=4)\n",
    "occurrences_df.to_excel(f'{DATA_FOLD}/{VERSION}/3.analysis/imputation_48/{DATASET}/tables/occurences_total.xlsx')\n",
    "occurences_df_rel = occurrences_df\n",
    "occurences_df_rel.iloc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour calculer le nombre de séjours uniques concernés\n",
    "def calculate_stays_by_consecutive_intervals(df, max_missing_values):\n",
    "    df = df.cast({'encounterId' : pl.Int32}).sort('encounterId', 'intervalle').to_pandas()\n",
    "    results = {}\n",
    "\n",
    "    for n in range(max_missing_values + 1):  # Tester chaque seuil de n variables manquantes\n",
    "        df[\"below_threshold\"] = df[\"total_missing\"] >= n\n",
    "\n",
    "        # Identifier les groupes consécutifs où `below_threshold` est True\n",
    "        df[\"group\"] = (df[\"below_threshold\"] != df[\"below_threshold\"].shift()).cumsum()\n",
    "        consecutive_counts = df[df[\"below_threshold\"]].groupby([\"group\", \"encounterId\"]).size()\n",
    "\n",
    "        # Associer les groupes d'heures à leur durée\n",
    "        durations = consecutive_counts.reset_index(name=\"duration\")\n",
    "        durations = durations.groupby(\"duration\")[\"encounterId\"].nunique()\n",
    "\n",
    "        # Stocker le nombre de séjours concernés pour chaque durée\n",
    "        results[n] = durations\n",
    "\n",
    "    # Convertir les résultats en DataFrame\n",
    "    results_df = pd.DataFrame(results).fillna(0).astype(int)\n",
    "    results_df.index.name = \"Consecutive Hours\"\n",
    "    results_df.columns.name = \"Max Missing Values\"\n",
    "    return results_df\n",
    "\n",
    "# Calcul des séjours concernés pour les seuils de 0 à 7 variables manquantes\n",
    "stays_df = calculate_stays_by_consecutive_intervals(data, max_missing_values=4)\n",
    "\n",
    "stays_df_rel = round(stays_df/data.unique('encounterId').shape[0]*100,1)\n",
    "stays_df.to_excel(f'{DATA_FOLD}/{VERSION}/3.analysis/imputation_48/{DATASET}/tables/occurences_par_séjours.xlsx')\n",
    "stays_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration de Seaborn\n",
    "sns.set_theme(style=\"whitegrid\", palette=\"pastel\")\n",
    "\n",
    "# Création de la figure\n",
    "fig, axes = plt.subplots(2, 1, figsize=(7, 10), sharex=False, sharey=False)\n",
    "\n",
    "fig.text(0.5, 0.95, f\"{DATASET.upper()}\", ha='center', va='center', fontsize=14, fontweight='bold')\n",
    "\n",
    "occurrences_df = calculate_consecutive_intervals(data, max_missing_values=4)\n",
    "# Graphique 1 : Nombre d'occurrences\n",
    "for n in occurrences_df.columns:\n",
    "    if n:\n",
    "        sns.lineplot(\n",
    "            x=occurences_df_rel.index,\n",
    "            y=occurences_df_rel[n],\n",
    "            ax=axes[0],\n",
    "            label=f\"{n} variables\",\n",
    "            marker =\"8\",\n",
    "            markeredgecolor='k'\n",
    "        )\n",
    "axes[0].set_xlabel(\"Durée des Intervalles Consécutifs (Heures)\")\n",
    "axes[0].set_ylabel(\"Nombre d'occurrences\")\n",
    "axes[0].set_xlim([0, 6])\n",
    "axes[0].set_ylim([0, 40000])\n",
    "axes[0].legend(title=\"Variables Manquantes\",  fontsize=8, title_fontsize=10)\n",
    "axes[0].grid(True)\n",
    "\n",
    "stays_df = calculate_stays_by_consecutive_intervals(data, max_missing_values=4)\n",
    "# Graphique 2 : Nombre de séjours concernés\n",
    "for n in stays_df.columns:\n",
    "    if n:\n",
    "        sns.lineplot(\n",
    "            x=stays_df.index,\n",
    "            y=stays_df[n],\n",
    "            ax=axes[1],\n",
    "            label=f\"{n} Variables Manquantes\",\n",
    "            marker=\"8\",\n",
    "            markeredgecolor='k'\n",
    "        )\n",
    "axes[1].set_xlabel(\"Durée des Intervalles Consécutifs (Heures)\")\n",
    "axes[1].set_ylabel(\"Nombre de séjours\")\n",
    "axes[1].set_xlim([0, 6])\n",
    "axes[1].set_ylim([0, 30000])\n",
    "axes[1].legend(title=\"Variables Manquantes\",  fontsize=8, title_fontsize=10)\n",
    "axes[1].grid(True)\n",
    "\n",
    "\n",
    "# Ajustement de l'affichage\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])  # Ajuster pour le titre global\n",
    "\n",
    "plt.show()\n",
    "# \"Analyse des Intervalles Consécutifs par Seuil de Variables Manquantes\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration for Seaborn\n",
    "sns.set_theme(style=\"whitegrid\", palette=\"pastel\")\n",
    "\n",
    "markers = [\"o\", \"s\", \"D\", \"^\", \"v\", \"<\", \">\", \"p\", \"h\", \"*\"]\n",
    "\n",
    "# Function to plot data on a specific axis\n",
    "def plot_data(ax, df, x_label, y_label, x_limit, y_limit, legend_title, remove_yticks=False):\n",
    "    for n in df.columns:\n",
    "        if n:\n",
    "            sns.lineplot(\n",
    "                x=df.index,\n",
    "                y=df[n],\n",
    "                ax=ax,\n",
    "                label=f\"{n} Missing Variables\",\n",
    "                marker=markers[n],\n",
    "                markeredgecolor='k',\n",
    "                linestyle=\"-\"\n",
    "            )\n",
    "    ax.set_xlabel(x_label)\n",
    "    if not remove_yticks:\n",
    "        ax.set_ylabel(y_label)\n",
    "    else:\n",
    "        ax.set_yticks([])\n",
    "        ax.set_ylabel(\"\")\n",
    "    ax.set_xlim(x_limit)\n",
    "    ax.set_ylim(y_limit)\n",
    "    ax.legend(title=legend_title, fontsize=8, title_fontsize=10)\n",
    "    ax.grid(False)\n",
    "\n",
    "# Create the figure\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10), sharex=True)\n",
    "\n",
    "# Add subtitles above the vertical axes\n",
    "fig.text(0.25, 0.95, \"MIMIC-IV\", ha='center', va='center', fontsize=14, fontweight='bold')\n",
    "fig.text(0.75, 0.95, \"CHU\", ha='center', va='center', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Plot data for MIMIC-IV\n",
    "occurrences_df_mimic = calculate_consecutive_intervals(data_mimic, max_missing_values=6)\n",
    "plot_data(\n",
    "    axes[0, 0], occurrences_df_mimic,\n",
    "    x_label=\"Consecutive Interval Duration (Hours)\",\n",
    "    y_label=\"Number of Occurrences\",\n",
    "    x_limit=[0, 7],\n",
    "    y_limit=[0, 60000],\n",
    "    legend_title=\"Missing Variables\"\n",
    ")\n",
    "\n",
    "stays_df_mimic = calculate_stays_by_consecutive_intervals(data_mimic, max_missing_values=6)\n",
    "plot_data(\n",
    "    axes[1, 0], stays_df_mimic,\n",
    "    x_label=\"Consecutive Interval Duration (Hours)\",\n",
    "    y_label=\"Number of Stays\",\n",
    "    x_limit=[0, 7],\n",
    "    y_limit=[0, 30000],\n",
    "    legend_title=\"Missing Variables\"\n",
    ")\n",
    "\n",
    "# Plot data for CHU (Remove yticks and ylabel)\n",
    "occurrences_df_chu = calculate_consecutive_intervals(data_chu, max_missing_values=6)\n",
    "plot_data(\n",
    "    axes[0, 1], occurrences_df_chu,\n",
    "    x_label=\"Consecutive Interval Duration (Hours)\",\n",
    "    y_label=\"Number of Occurrences\",\n",
    "    x_limit=[0, 7],\n",
    "    y_limit=[0, 60000],\n",
    "    legend_title=\"Missing Variables\",\n",
    "    remove_yticks=True\n",
    ")\n",
    "\n",
    "stays_df_chu = calculate_stays_by_consecutive_intervals(data_chu, max_missing_values=6)\n",
    "plot_data(\n",
    "    axes[1, 1], stays_df_chu,\n",
    "    x_label=\"Consecutive Interval Duration (Hours)\",\n",
    "    y_label=\"Number of Stays\",\n",
    "    x_limit=[0, 7],\n",
    "    y_limit=[0, 30000],\n",
    "    legend_title=\"Missing Variables\",\n",
    "    remove_yticks=True\n",
    ")\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.9])  # Adjust for the global title\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "occurrences_df = calculate_consecutive_intervals(data_chu, max_missing_values=6)\n",
    "# Graphique 1 : Nombre d'occurrences\n",
    "for n in occurrences_df.columns:\n",
    "    if n:\n",
    "        sns.lineplot(\n",
    "            x=occurences_df_rel.index,\n",
    "            y=occurences_df_rel[n],\n",
    "            ax=axes[0,1],\n",
    "            label=f\"{n} variables\",\n",
    "            marker =\"8\",\n",
    "            markeredgecolor='k'\n",
    "        )\n",
    "axes[0,1].set_xlabel(\"Durée des Intervalles Consécutifs (Heures)\")\n",
    "axes[0,1].set_ylabel(\"Nombre d'occurrences\")\n",
    "axes[0,1].set_xlim([0, 7])\n",
    "axes[0,1].set_ylim([0, 60000])\n",
    "axes[0,1].legend(title=\"Variables Manquantes\",  fontsize=8, title_fontsize=10)\n",
    "axes[0,1].grid(True)\n",
    "\n",
    "stays_df = calculate_stays_by_consecutive_intervals(data_chu, max_missing_values=6)\n",
    "# Graphique 2 : Nombre de séjours concernés\n",
    "for n in stays_df.columns:\n",
    "    if n:\n",
    "        sns.lineplot(\n",
    "            x=stays_df.index,\n",
    "            y=stays_df[n],\n",
    "            ax=axes[1,1],\n",
    "            label=f\"{n} Variables Manquantes\",\n",
    "            marker=\"8\",\n",
    "            markeredgecolor='k'\n",
    "        )\n",
    "axes[1,1].set_xlabel(\"Durée des Intervalles Consécutifs (Heures)\")\n",
    "axes[1,1].set_ylabel(\"Nombre de séjours\")\n",
    "axes[1,1].set_xlim([0, 7])\n",
    "axes[1,1].set_ylim([0, 30000])\n",
    "axes[1,1].legend(title=\"Variables Manquantes\",  fontsize=8, title_fontsize=10)\n",
    "axes[1,1].grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculer la moyenne des données manquantes pour chaque intervalle de temps et chaque variable\n",
    "missing_means = (\n",
    "    data\n",
    "    .group_by(\"intervalle\")\n",
    "    .agg([\n",
    "        pl.col(\"fr\").is_null().cast(pl.UInt32).mean().alias(\"mean_fr_missing\"),\n",
    "        pl.col(\"heart_rate\").is_null().cast(pl.UInt32).mean().alias(\"mean_heart_rate_missing\"),\n",
    "        pl.col(\"spo2\").is_null().cast(pl.UInt32).mean().alias(\"mean_spo2_missing\"),\n",
    "        pl.col(\"pam\").is_null().cast(pl.UInt32).mean().alias(\"mean_pam_missing\"),\n",
    "        pl.col(\"total_missing\").mean().alias(\"mean_total_missing\")\n",
    "    ])\n",
    "    .sort(\"intervalle\")\n",
    ")\n",
    "\n",
    "# Convertir en DataFrame Pandas pour la visualisation\n",
    "missing_means_df = missing_means.to_pandas()\n",
    "\n",
    "# Tracer le lineplot avec Seaborn\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.lineplot(data=missing_means_df, x=\"intervalle\", y=\"mean_fr_missing\", label=\"Missing RR\")\n",
    "sns.lineplot(data=missing_means_df, x=\"intervalle\", y=\"mean_heart_rate_missing\", label=\"Missing HR\")\n",
    "sns.lineplot(data=missing_means_df, x=\"intervalle\", y=\"mean_spo2_missing\", label=\"Missing SpO2\")\n",
    "sns.lineplot(data=missing_means_df, x=\"intervalle\", y=\"mean_pam_missing\", label=\"Missing MBP\")\n",
    "sns.lineplot(data=missing_means_df, x=\"intervalle\", y=\"mean_total_missing\", \n",
    "             label=\"Total Missing\", linestyle=\"--\", linewidth=2.5, color='black')\n",
    "\n",
    "# Ajouter des labels et un titre\n",
    "plt.xlabel(\"Time Interval (hours)\")\n",
    "plt.ylabel(\"Average Number of Missing Data\")\n",
    "plt.title(\"Average Number of Missing Data Over Time\")\n",
    "plt.legend()\n",
    "plt.grid(False)\n",
    "\n",
    "# Afficher le graphique\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_chu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import polars as pl\n",
    "\n",
    "# Example data processing for MIMIC and CHU (replace with actual data)\n",
    "# mimic_data = ...\n",
    "# chu_data = ...\n",
    "\n",
    "# Function to calculate mean missing data for each intervalle and variable\n",
    "def calculate_missing_means(data):\n",
    "    return (\n",
    "        data\n",
    "        .group_by(\"intervalle\")\n",
    "        .agg([\n",
    "            pl.col(\"fr\").is_null().cast(pl.UInt32).mean().alias(\"mean_fr_missing\"),\n",
    "            pl.col(\"heart_rate\").is_null().cast(pl.UInt32).mean().alias(\"mean_heart_rate_missing\"),\n",
    "            pl.col(\"spo2\").is_null().cast(pl.UInt32).mean().alias(\"mean_spo2_missing\"),\n",
    "            pl.col(\"pam\").is_null().cast(pl.UInt32).mean().alias(\"mean_MBP_missing\"),\n",
    "\n",
    "            pl.col(\"total_missing\").mean().alias(\"mean_total_missing\")\n",
    "        ])\n",
    "        .sort(\"intervalle\")\n",
    "    ).to_pandas()\n",
    "\n",
    "# Process data for MIMIC and CHU\n",
    "\n",
    "missing_means= calculate_missing_means(data)\n",
    "\n",
    "# Set up the figure with two vertical subplots\n",
    "fig, axes = plt.subplots(2, 1, figsize=(12, 12), sharex=False)\n",
    "\n",
    "# Plot for MIMIC dataset\n",
    "sns.lineplot(data=missing_means, x=\"intervalle\", y=\"mean_fr_missing\", ax=axes[0], label=\"FR Missing\")\n",
    "sns.lineplot(data=missing_means, x=\"intervalle\", y=\"mean_heart_rate_missing\", ax=axes[0], label=\"Heart Rate Missing\")\n",
    "sns.lineplot(data=missing_means, x=\"intervalle\", y=\"mean_spo2_missing\", ax=axes[0], label=\"SpO2 Missing\")\n",
    "sns.lineplot(data=missing_means, x=\"intervalle\", y=\"mean_MBP_missing\", ax=axes[0], label=\"MBP Missing\")\n",
    "sns.lineplot(data=missing_means, x=\"intervalle\", y=\"mean_total_missing\", ax=axes[0], label=\"Total Missing\", linestyle=\"--\", linewidth=2.5, color=\"black\")\n",
    "axes[0].set_title(f\"Average Missing Data Over Time - {DATASET.upper()} Dataset\")\n",
    "axes[0].set_ylabel(\"Mean Missing Values\")\n",
    "axes[0].set_xlabel(\"Time (h)\")\n",
    "axes[0].grid(False)\n",
    "axes[0].legend()\n",
    "\n",
    "\n",
    "\n",
    "# Adjust layout and show\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(data_merge['spo2'] < 80).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_chu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cols in data_features:\n",
    "    # Calcul des statistiques pour chaque dataset\n",
    "    chu_mean = data_chu[cols].mean()\n",
    "    chu_std = data_chu[cols].std()\n",
    "    mimic_mean = data_mimic[cols].mean()\n",
    "    mimic_std = data_mimic[cols].std()\n",
    "\n",
    "    # Lignes verticales pour chaque dataset\n",
    "    chu_line_1 = round(chu_mean - 3 * chu_std, 2)\n",
    "    chu_line_2 = round(chu_mean + 3 * chu_std, 2)\n",
    "    mimic_line_1 = round(mimic_mean - 3 * mimic_std, 2)\n",
    "    mimic_line_2 = round(mimic_mean + 3 * mimic_std, 2)\n",
    "\n",
    "    # Création des sous-plots côte à côte\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(20, 10), sharey=True)\n",
    "    \n",
    "    # Histogramme pour mimic\n",
    "    if cols == 'spo2' :\n",
    "        sns.histplot(data_mimic, x=cols, kde=True, ax=axes[0], color='skyblue', binwidth=((mimic_line_2-mimic_line_1)/10), stat='probability')\n",
    "    else :\n",
    "        sns.histplot(data_mimic, x=cols, kde=True, ax=axes[0], color='skyblue', binwidth=((mimic_line_2-mimic_line_1)/20), stat='probability')\n",
    "    axes[0].axvline(mimic_line_1, color='red', linestyle='--')\n",
    "    axes[0].axvline(mimic_line_2, color='green', linestyle='--')\n",
    "    axes[0].text(mimic_line_1, axes[0].get_ylim()[1] * 0.9, f'{mimic_line_1}', color='red')\n",
    "    axes[0].text(mimic_line_2, axes[0].get_ylim()[1] * 0.9, f'{mimic_line_2}', color='green')\n",
    "    axes[0].set_title(f'Distribution de {cols} - MIMIC', fontsize=14)\n",
    "    axes[0].set_xlim(mimic_line_1-mimic_std, mimic_line_2+mimic_std)\n",
    "\n",
    "    # Histogramme pour chu\n",
    "    sns.histplot(data_chu, x=cols, kde=True, ax=axes[1], color='orange', binwidth=(chu_line_2-chu_line_1)/20, stat='probability')\n",
    "    axes[1].axvline(chu_line_1, color='red', linestyle='--')\n",
    "    axes[1].axvline(chu_line_2, color='green', linestyle='--')\n",
    "    axes[1].text(chu_line_1, axes[1].get_ylim()[1] * 0.9, f'{chu_line_1}', color='red')\n",
    "    axes[1].text(chu_line_2, axes[1].get_ylim()[1] * 0.9, f'{chu_line_2}', color='green')\n",
    "    axes[1].set_title(f'Distribution de {cols} - CHU', fontsize=14)\n",
    "    axes[0].set_xlim(chu_line_1-chu_std, chu_line_2+chu_std)\n",
    "\n",
    "    # Ajustement et affichage\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    fig = plt.figure()\n",
    "    fig.savefig(f'{DATA_FOLD}/{VERSION}/3.analysis/imputation_48/global/features_distributions/{cols}_hist.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relation données manquantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_chu.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_chu_pd = data_chu.select('encounterId',\n",
    " 'intervalle',\n",
    " 'heart_rate',\n",
    " 'spo2',\n",
    " 'fr',\n",
    " 'pad',\n",
    " 'pam',\n",
    " 'pas').to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_chu_null = data_chu_pd.copy()\n",
    "data_chu_null[data_features] = data_chu_null[data_features].isnull()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
